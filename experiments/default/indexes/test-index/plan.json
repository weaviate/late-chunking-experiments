{
    "config": {
        "query_token_id": "[unused0]",
        "doc_token_id": "[unused1]",
        "query_token": "[Q]",
        "doc_token": "[D]",
        "ncells": null,
        "centroid_score_threshold": null,
        "ndocs": null,
        "load_index_with_mmap": false,
        "index_path": null,
        "index_bsize": 64,
        "nbits": 2,
        "kmeans_niters": 4,
        "resume": false,
        "pool_factor": 1,
        "clustering_mode": "hierarchical",
        "protected_tokens": 0,
        "similarity": "cosine",
        "bsize": 64,
        "accumsteps": 1,
        "lr": 1e-5,
        "maxsteps": 400000,
        "save_every": null,
        "warmup": 20000,
        "warmup_bert": null,
        "relu": false,
        "nway": 64,
        "use_ib_negatives": true,
        "reranker": false,
        "distillation_alpha": 1.0,
        "ignore_scores": false,
        "model_name": null,
        "query_maxlen": 32,
        "attend_to_mask_tokens": false,
        "interaction": "colbert",
        "dim": 128,
        "doc_maxlen": 128,
        "mask_punctuation": true,
        "checkpoint": "jinaai\/jina-colbert-v1-en",
        "triples": "data\/MSMARCO\/colbertv2.train.json",
        "collection": [
            "As Weaviate celebrates its fifth anniversary, we've had the privilege of collaborating with tens of thousands of developers, gaining invaluable insights into the evolving landscape of AI projects and strategies. Our users constantly push the boundaries of what\u2019s possible. As they continue to scale their applications in production, they guide the evolution of our product and the market itself. The need for optionality One of the main reasons developers choose Weaviate is the optionality it offers in terms of machine learning models, frameworks, and deployment. With new AI models and tools emerging daily, it's crucial to build systems that allow flexibility for tech stacks to evolve. This optionality, combined with ease of use, helps teams scale AI prototypes into production faster. Flexibility is also vital when it comes to architecture. Different use cases have different requirements. For example, we work with many software companies and those operating in regulated industries. They often require multi-tenancy to isolate data and maintain compliance. When building a Retrieval Augmented Generation (RAG) application, using account or user-specific data to contextualize results, data must remain within a dedicated tenant for its user group. Weaviate\u2019s native, multi-tenant architecture shines for customers who need to prioritize data privacy while maintaining fast retrieval and accuracy. On the other hand, we support some very large scale single-tenant use cases that orient toward real-time data access. Many of these are in e-commerce and industries that compete on speed and customer experience. Even the slightest latency can send their users looking elsewhere. These use cases leverage our HNSW index on hot storage and vector compression to ensure low latency. The point is, there is no one-size-fits-all solution so optionality is key. I\u2019m very proud that through learning from our customers and community, we\u2019re building a solution that supports diverse use cases and the evolving needs of developers. Introducing hot, warm, and cold storage tiers It\u2019s amazing to see our customers' products gain popularity, attracting more users, and in many cases, tenants. However, as multi-tenant use cases scale, infrastructure costs can quickly become prohibitive. Since multi-tenancy is a core tenet of our architecture, the next logical step for us was to build a way to help customers drive more efficient resource consumption. We\u2019re pleased to offer tenant offloading and hot, warm, and cold storage tiers as part of our latest release. Weaviate users (Open Source and Enterprise Cloud) can now deactivate or offload tenants to less-expensive warm or cold storage and reactivate them dynamically, based on the unique patterns of their use case. Here\u2019s what it might look like in practice: One of our customers develops an email platform with tens of thousands of users. 80% of their users are only active during a 12-hour window (US business hours). With our new storage tiers, they can offload tenants to cold storage to save on infrastructure costs when users are inactive. When a user comes online, they can quickly warm up the tenant. This way they reduce storage costs while still offering performance that meets the needs of their customers. alt The Weaviate AI Unit To adapt to this product change and the evolving AI stack, we\u2019ve introduced a new pricing unit to our Enterprise Cloud offering. An AI Unit (AIU) is a Weaviate-specific unit that can be applied to hot, warm, and cold storage tiers and compute costs. AIUs enable customers to better monitor usage and improve budgeting. In addition to resource costs, AIUs will apply to new AI-native Apps as they are released (more on that next). Apps and tools to fuel AI-native development As we continue to listen to our community, it\u2019s clear that developers need an AI-native framework offering not just flexibility, but also modular GUI tools to interact with their data and accelerate their use cases. We\u2019re excited about a new line of AI-native apps and tools that will help developers and business users accelerate common use cases. Recommender App Our first app is a Recommender service, now in private beta. The Recommender is a fully managed, low-code way to build scalable recommendation systems. It offers configurable endpoints for item-to-item, item-to-user, and user-to-user recommendation scenarios across multimodal data. Sign up for the private beta here, and stay tuned for more Apps updates coming soon. alt Weaviate Cloud Tools Lastly, new Weaviate Cloud Tools give developers and non-technical users an easier way to manage, explore, and interact with their data within Weaviate Cloud. The Query and Collections tools are available now in the Weaviate Cloud Console. It\u2019s been an exciting few months, and I\u2019m ecstatic to continue learning from our community and empowering developers to build the future of AI-native possibilities. To dive deeper into our latest product updates, join our upcoming webinar."
        ],
        "queries": "data\/MSMARCO\/queries.train.tsv",
        "index_name": "test-index",
        "overwrite": false,
        "root": "\/Users\/charlespierse\/Documents\/weaviate-workspace\/late-chunking-experiments\/experiments",
        "experiment": "default",
        "index_root": null,
        "name": "2024-08\/29\/12.26.14",
        "rank": 0,
        "nranks": 1,
        "amp": true,
        "gpus": 0,
        "avoid_fork_if_possible": false
    },
    "num_chunks": 1,
    "num_partitions": 128,
    "num_embeddings_est": 116.0,
    "avg_doclen_est": 116.0
}
